<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Harish">
<meta name="dcterms.date" content="2025-04-10">

<title>Harish B - Introduction to Language AI &amp; LLM</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Harish B</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">pet projects</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harishb00"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/harishb00/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#language-ai" id="toc-language-ai" class="nav-link active" data-scroll-target="#language-ai">Language AI</a></li>
  <li><a href="#history" id="toc-history" class="nav-link" data-scroll-target="#history">History</a></li>
  <li><a href="#representing-language" id="toc-representing-language" class="nav-link" data-scroll-target="#representing-language">Representing Language</a>
  <ul class="collapse">
  <li><a href="#bag-of-words-2000s" id="toc-bag-of-words-2000s" class="nav-link" data-scroll-target="#bag-of-words-2000s">Bag-of-Words, 2000s</a></li>
  <li><a href="#word2vec-2013" id="toc-word2vec-2013" class="nav-link" data-scroll-target="#word2vec-2013">Word2Vec, 2013</a></li>
  <li><a href="#attention-2014" id="toc-attention-2014" class="nav-link" data-scroll-target="#attention-2014">Attention, 2014</a></li>
  <li><a href="#attention-is-all-you-need-2017" id="toc-attention-is-all-you-need-2017" class="nav-link" data-scroll-target="#attention-is-all-you-need-2017">Attention Is All You Need, 2017</a></li>
  <li><a href="#bert-2018" id="toc-bert-2018" class="nav-link" data-scroll-target="#bert-2018">BERT, 2018</a>
  <ul class="collapse">
  <li><a href="#encoder-only-models-representation-models" id="toc-encoder-only-models-representation-models" class="nav-link" data-scroll-target="#encoder-only-models-representation-models">Encoder-only Models: Representation Models</a></li>
  </ul></li>
  <li><a href="#gpt-1-2018" id="toc-gpt-1-2018" class="nav-link" data-scroll-target="#gpt-1-2018">GPT-1, 2018</a>
  <ul class="collapse">
  <li><a href="#decoder-only-models-generative-models" id="toc-decoder-only-models-generative-models" class="nav-link" data-scroll-target="#decoder-only-models-generative-models">Decoder-only Models: Generative Models</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#generative-llms" id="toc-generative-llms" class="nav-link" data-scroll-target="#generative-llms">Generative LLMs</a>
  <ul class="collapse">
  <li><a href="#what-is-large-in-llms" id="toc-what-is-large-in-llms" class="nav-link" data-scroll-target="#what-is-large-in-llms">What is Large in LLMs?</a></li>
  </ul></li>
  <li><a href="#generative-ai-gen-ai" id="toc-generative-ai-gen-ai" class="nav-link" data-scroll-target="#generative-ai-gen-ai">Generative AI (Gen AI)</a>
  <ul class="collapse">
  <li><a href="#model-vs.-product" id="toc-model-vs.-product" class="nav-link" data-scroll-target="#model-vs.-product">Model vs.&nbsp;Product</a></li>
  </ul></li>
  <li><a href="#accessing-llms" id="toc-accessing-llms" class="nav-link" data-scroll-target="#accessing-llms">Accessing LLMs</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Introduction to Language AI &amp; LLM</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Language AI</div>
    <div class="quarto-category">LLM</div>
    <div class="quarto-category">Gen AI</div>
    <div class="quarto-category">AI</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Harish </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 10, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>This notebook is heavily inspired from <a href="https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/">Chapter 1 - Hands-on LLM</a> book by <strong>Jay Alammar</strong> and <strong>Maarten Grootendorst</strong> and also my notes on the chapter.</p>
</blockquote>
<section id="language-ai" class="level1">
<h1>Language AI</h1>
<ul>
<li><p><strong>Artificial Intelligence (AI)</strong> is often used to describe computer systems dedicated to performing tasks close to human intelligence, such as speech recognition, language translation, and visual perception.</p></li>
<li><p><strong>Language AI</strong> refers to a subfield of AI that focuses on developing technologies capable of understanding, processing, and generating human language. It can be used interchangeably with <strong>Natural Language Processing</strong>.</p></li>
</ul>
</section>
<section id="history" class="level1">
<h1>History</h1>
<ul>
<li><p>Lot of research and development has happened in the field of Language AI aiming <strong>to represent and generate language</strong>. Below image shows those developments over the years.</p>
<p><img src="./assets/lang-ai-evolution.png" class="img-fluid" alt="Language AI Evolution"><br> <em>Source: <a href="https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/">Chapter 1 - Hands-on LLM</a></em></p></li>
<li><p><strong>Text is unstructured</strong> in nature and loses its meaning when represented by zeros and ones (individual characters). As a result, throughout the history of Language AI, there has been a large focus on <strong>representing language in a structured manner so that it can more easily be used by computers</strong>.</p></li>
</ul>
</section>
<section id="representing-language" class="level1">
<h1>Representing Language</h1>
<section id="bag-of-words-2000s" class="level2">
<h2 class="anchored" data-anchor-id="bag-of-words-2000s">Bag-of-Words, 2000s</h2>
<ul>
<li>Bag-of-Words is a classic method (became popular in early 2000s) to represent unstructured text in numbers.</li>
<li><strong>How it works?</strong> <img src="./assets/bow-alg.png" class="img-fluid" alt="Bag of Words Algorithm"></li>
<li>As a result, a bag-of-words model aims <strong>to create representations of text in the form of numbers</strong>, also called vectors or <strong>vector representations</strong>.</li>
<li>Since these models are primarily used for representing text, they are referred to as <strong>representation models</strong>.</li>
<li><strong>Limitation</strong>: It considers language to be nothing more than bag of words (literally!) and ignores the order of words, the semantic nature, or meaning, of text.</li>
</ul>
</section>
<section id="word2vec-2013" class="level2">
<h2 class="anchored" data-anchor-id="word2vec-2013">Word2Vec, 2013</h2>
<blockquote class="blockquote">
<p>💡<a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a></p>
</blockquote>
<ul>
<li><p>Released in 2013, <em>word2vec</em> was one of the first successful attempts at capturing the meaning of text in <strong><em>embeddings</em></strong>.</p></li>
<li><p><strong>Embeddings</strong> are vector representations of data that attempt to capture its meaning.</p></li>
<li><p><strong>How it works?</strong></p>
<ol type="1">
<li><strong>Training</strong>: It takes a large corpus of text (like Wikipedia) and learns to predict the context of a word given its surrounding words.</li>
<li><strong>Representation</strong>: The model learns to represent words in a dense vector space where similar words are close to each other.</li>
</ol></li>
<li><p>As shown in the below image, the word <strong>embeddings are learned</strong> in such a way that <strong>similar words are close to each other in the vector space</strong>.</p>
<p><img src="./assets/word2vec-vec-space.png" class="img-fluid" alt="image-2.png"><br> <em>Source: <a href="https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/">Chapter 1 - Hands-on LLM</a></em></p></li>
<li><p><strong>Limitation</strong>: <em>word2vec</em> creates <strong>static</strong>, downloadable <strong>representations of words</strong>. For example, the word “bank” will always have the <strong>same embedding, regardless of the context</strong> in which it is used. However “bank” refers to both a financial bank as well as the bank of a river. This is a limitation of <em>word2vec</em> and other static word embedding models.</p></li>
</ul>
</section>
<section id="attention-2014" class="level2">
<h2 class="anchored" data-anchor-id="attention-2014">Attention, 2014</h2>
<blockquote class="blockquote">
<p>💡<a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a></p>
</blockquote>
<ul>
<li>To overcome the limitation mentioned above, the <strong>Attention</strong> mechanism was introduced.</li>
<li>Attention selectively determines which words are most important in a given sentence and focuses on them. It allows the model to weigh the importance of different words in a sentence when generating an output.</li>
<li>By adding these attention mechanisms to the decoder step, the RNN can generate signals for each input word in the sequence, allowing it to focus on the most relevant words when generating the output.</li>
<li>Instead of passing only a context embedding to the decoder, the hidden states of all input words are passed.</li>
<li><strong>Limitation</strong>: The attention mechanism is still limited by the sequential nature of RNNs, which makes it difficult to parallelize the training process.</li>
</ul>
</section>
<section id="attention-is-all-you-need-2017" class="level2">
<h2 class="anchored" data-anchor-id="attention-is-all-you-need-2017">Attention Is All You Need, 2017</h2>
<blockquote class="blockquote">
<p>💡<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></p>
</blockquote>
<ul>
<li>The <strong>Transformer</strong> architecture was introduced in 2017, which is based entirely on the attention mechanism and does not use RNNs at all.</li>
<li>The transformer architecture consists of an <strong>encoder</strong> and a <strong>decoder</strong>. The encoder takes the input sequence and generates a set of attention scores, which are then used by the decoder to generate the output sequence.</li>
<li>The transformer architecture allows for parallelization of the training process, making it much faster and more efficient than RNNs.</li>
<li>The transformer architecture has become the foundation for many state-of-the-art models in NLP, including BERT, GPT-2, and T5.</li>
</ul>
</section>
<section id="bert-2018" class="level2">
<h2 class="anchored" data-anchor-id="bert-2018">BERT, 2018</h2>
<blockquote class="blockquote">
<p>💡<a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p>
</blockquote>
<ul>
<li>In 2018, a new <strong>encoder-stacked architecture</strong> called <strong>Bidirectional Encoder Representations from Transformers (BERT)</strong> was introduced that could be leveraged for a wide variety of tasks and would serve as the foundation of Language AI for years to come.</li>
<li>BERT is an encoder-only architecture that focuses on representing language.</li>
<li><strong>How training works?</strong> It is trained on a large corpus of text using a <strong>masked language modeling</strong> objective, which means that it learns <strong>to predict missing words in a sentence based on the context of the surrounding words</strong>.</li>
<li>This prediction task is difficult but allows BERT to create more accurate (intermediate) representations of the input.</li>
<li>This architecture and training procedure makes BERT and related architectures incredible at representing contextual language.</li>
</ul>
<section id="encoder-only-models-representation-models" class="level3">
<h3 class="anchored" data-anchor-id="encoder-only-models-representation-models">Encoder-only Models: Representation Models</h3>
<p>The original <em>Transformer</em> model is an encoder-decoder architecture that serves translation tasks well but cannot easily be used for other tasks, like text-classification or semantic search.</p>
<p>Representation models focus on representing language, by creating embeddings, and do not generate text. These embeddings can be used for a variety of tasks, including text classification, semantic search, and clustering.</p>
</section>
</section>
<section id="gpt-1-2018" class="level2">
<h2 class="anchored" data-anchor-id="gpt-1-2018">GPT-1, 2018</h2>
<blockquote class="blockquote">
<p>💡<a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a></p>
</blockquote>
<ul>
<li>In 2018, OpenAI released the first version of the <strong>Generative Pre-trained Transformer (GPT)</strong> model, which is a decoder-only architecture that focuses on generating text.</li>
<li>GPT-1 was trained on a corpus of 7,000 books and Common Crawl, a large dataset of web pages. The resulting model consisted of 117 million parameters.</li>
<li>GPT-1 was trained using a <strong>language modeling objective</strong>, which means that it learns to predict the next word in a sentence given the previous words.</li>
<li>Increase in the number of parameters and the size of the training corpus led to a significant improvement in performance on a variety of NLP tasks.</li>
<li>So, larger models were trained using the same architecture, including GPT-2 with 1.5 billion parameters and GPT-3 with 175 billion parameters.</li>
</ul>
<section id="decoder-only-models-generative-models" class="level3">
<h3 class="anchored" data-anchor-id="decoder-only-models-generative-models">Decoder-only Models: Generative Models</h3>
<p>In contrast with Encoder-only Models, Generative Models focus primarily on generating text and typically are not trained to generate embeddings.</p>
</section>
</section>
</section>
<section id="generative-llms" class="level1">
<h1>Generative LLMs</h1>
<p>The generative decoder-only models, especially the “larger” models, are commonly referred to as Large Language Models (LLMs).</p>
<ul>
<li><strong>Generative LLMs</strong>, as sequence-to-sequence machines, <strong>take in some text and attempts to autocomplete it</strong>.</li>
<li>Instead of completing a text, <strong><em>what if they could be trained to answer questions? By fine-tuning these models, we can create INSTRUCT or CHAT models that can follow direction</em></strong>.</li>
</ul>
<section id="what-is-large-in-llms" class="level2">
<h2 class="anchored" data-anchor-id="what-is-large-in-llms">What is Large in LLMs?</h2>
<p>Below are some of the points about LLMs in the book Hands-on LLM.</p>
<blockquote class="blockquote">
<p>What if we create a model with the <strong>same capabilities as GPT-3 but 10 times smaller?</strong> Would such a model fall outside the “Large” Language Model categorization?</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>“Large”</strong> is arbitrary and what might be considered a <strong>large model today could be small tomorrow</strong>. There are currently many names for the same thing and to us, <strong>“Large Language Models” are also models that do not generate text and can be run on consumer hardware</strong>.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Even encoder-only models can be referred to as LLMs, but the term is more commonly used for generative models</strong>.</p>
</blockquote>
</section>
</section>
<section id="generative-ai-gen-ai" class="level1">
<h1>Generative AI (Gen AI)</h1>
<p>The impact of these generative models led to a new wave of interest in the field of AI, often referred to as Generative AI. <strong>Generative AI refers to the use of AI models to generate content, such as text, images, music, and more</strong>.</p>
<p>There are many companies and startups that are <strong>building products and services</strong> based <strong>on Generative AI models</strong>, including OpenAI, Google, Microsoft, and many others.</p>
<section id="model-vs.-product" class="level2">
<h2 class="anchored" data-anchor-id="model-vs.-product">Model vs.&nbsp;Product</h2>
<ul>
<li>Model is the underlying technology/architecture, while the product is the application that uses the technology to provide value to users.</li>
<li>The following table shows few examples of models and products.</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th>Model</th>
<th>Product</th>
<th>Company</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GPT-3</td>
<td>ChatGPT</td>
<td>OpenAI</td>
</tr>
<tr class="even">
<td>Mistral</td>
<td>Le Chat</td>
<td>Mistral</td>
</tr>
<tr class="odd">
<td>Anthropic</td>
<td>Claude</td>
<td>Anthropic</td>
</tr>
<tr class="even">
<td>Gemini</td>
<td>Gemini</td>
<td>Google</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="accessing-llms" class="level1">
<h1>Accessing LLMs</h1>
<p>LLMs can be accessed using GUIs or through APIs. The latter makes it possible for developers to build applications using LLMs. Having said that, we can categorize LLMs into two main categories:</p>
<table class="table">
<colgroup>
<col style="width: 60%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>proprietary (Private) Models</th>
<th>Open Models</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Closed Source LLMs</td>
<td>Open Source LLMs</td>
</tr>
<tr class="even">
<td>Weights and architecture are not shared with the public</td>
<td>Weights and architecture are shared with the public</td>
</tr>
<tr class="odd">
<td>Accessed through APIs provided by the companies that own them</td>
<td>Can be downloaded, modified, and used by anyone</td>
</tr>
<tr class="even">
<td><strong>Examples</strong>: OpenAI’s GPT-3, Anthropic’s Claude, Google’s Gemini</td>
<td><strong>Examples</strong>: Meta’s LLaMA, Mistral models, Cohere’s Command R, Microsoft’s Phi</td>
</tr>
<tr class="odd">
<td><strong>Advantage</strong>: Easy to use, no need to worry about infrastructure or maintenance</td>
<td><strong>Advantage</strong>: More control, can be fine-tuned for specific tasks, can be run on local hardware</td>
</tr>
<tr class="even">
<td><strong>Disadvantage</strong>: Limited customization, sharing private data with service provider</td>
<td><strong>Disadvantage</strong>: Need to manage infrastructure, maintenance, and updates</td>
</tr>
</tbody>
</table>
</section>
<section id="references" class="level1">
<h1>References</h1>
<ul>
<li><a href="https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/">Hands-On Large Language Models by Jay Alammar and Maarten Grootendorst</a></li>
<li>https://jonathan-hui.medium.com/nlp-word-embedding-glove-5e7f523999f6</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="harishb00/harishb00.github.io" data-repo-id="R_kgDOLlyWtg" data-category="General" data-category-id="DIC_kwDOLlyWts4CeW8Y" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->




</body></html>